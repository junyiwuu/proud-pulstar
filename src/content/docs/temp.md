---
title: temp1
---

 
aaa
## What is XR
extended reality.


VR
virtual reality

AR
argumented reality: virtual stuff added into the real world, not person inside the virtual world. overlay, not replacing

MR 
mixed reality.  between vr and real world. has occlusion and integration. occlusion lets virtual objects to be obscured by real objects.
occlusion allows the virtual env to be integrated with the real world, rather than the virtual world like vr
Digital objects can aware of the physical environment. You can interact wit both real and virtual objects simultaneously.




Morpheus technology, handle huge number of concurrent users and complex interactions

Different: epic games: engine powerd. developer using it to build
Msquared: internet like infrastructure that lets all metaverse worlds connect and scale. Focus on the backend.



---
## POSIX
ÊØîÂ¶ÇÂØπ‰∫éthreadÊù•ËØ¥ÔºåC++ÂíåPOSIXÊúâËá™Â∑±ÁöÑthreadÊñπÊ≥ï
**POSIX** style
```
#include <pthread.h>

void* work(void*) {
    printf("hi\n");
    return NULL;
}
int main() {
    pthread_t t;
    pthread_create(&t, NULL, work, NULL);
    pthread_join(t, NULL);
}
```
**C++** style

```
#include <thread>
#include <iostream>

void work() {
    std::cout << "hi\n";
}

int main() {
    std::thread t(work);
    t.join();
}
```

| Âú∫ÊôØ                    | ÈÄâË∞Å               |
| --------------------- | ---------------- |
| ÂÜôÊôÆÈÄöÂêéÂè∞ÊúçÂä°               | `std::thread`    |
| ÂÜô Vulkan ÂºïÊìéÔºàÂíå OS Êâì‰∫§ÈÅìÔºâ | POSIX ÂèØËÉΩÊõ¥È¶ô       |
| ÂÜôÊ∏∏ÊàèÂºïÊìéË∞ÉÂ∫¶Á≥ªÁªü             | Ê∑∑Áî® / ÂÆöÂà∂Á∫øÁ®ãÊ±†       |
| ÂÜô HTTP server„ÄÅÊï∞ÊçÆÂ∫ìÂºïÊìé   | POSIX often used |
| Linux kernel Âë®Ëæπ       | POSIX            |

---

---
## Register

**What is register:**
ÂØÑÂ≠òÂô®(register) Â∞±ÊòØ CPU ÈáåÈù¢Ë∂ÖÈ´òÈÄüÁöÑÂ∞èÊ†ºÂ≠êÔºåÁî®Êù•ÊîæÈ©¨‰∏äË¶ÅÁÆóÁöÑ‰∏úË•ø„ÄÇ
ÁÆó a+b Êó∂Ôºåa Âíå b ‰ºöÂÖàÊîæËøõÂØÑÂ≠òÂô®ÔºåÁÑ∂Âêé CPU Âú®ÂØÑÂ≠òÂô®ÈáåÁÆó„ÄÇ

| ÂØÑÂ≠òÂô®Á±ªÂûã               | Âπ≤ÂòõÁöÑ              |
| ------------------- | ---------------- |
| ÈÄöÁî®ÂØÑÂ≠òÂô® (RAX, RBX...) | ÊîæËÆ°ÁÆóÁî®ÁöÑÊï∞Ôºà‰Ω†ËØ¥ÁöÑ a+bÔºâ  |
| Êåá‰ª§ÂØÑÂ≠òÂô® RIP           | Â≠òÁ®ãÂ∫èÊâßË°åÂà∞Âì™‰∏ÄË°å        |
| Ê†àÊåáÈíà RSP             | ÊåáÂêëÂΩìÂâçÊ†à‰ΩçÁΩÆ          |
| Âü∫ÂùÄÂØÑÂ≠òÂô® RBP           | Â∏ÆÂä©ÁÆ°ÁêÜÂáΩÊï∞Ê†àÂ∏ß         |
| ÂèÇÊï∞ÂØÑÂ≠òÂô® RDI, RSI...   | ÂáΩÊï∞ÂèÇÊï∞‰ªéËøôÈáå‰º†ÈÄí        |
| ËøîÂõûÂØÑÂ≠òÂô® RAX           | ÂáΩÊï∞ËøîÂõûÂÄº‰ªéËøôÈáåÂõû        |
| Ê†áÂøóÂØÑÂ≠òÂô® FLAGS         | Â≠òÂÇ®ÊØîËæÉÁªìÊûúÔºåÊØîÂ¶Ç > < == |
‰∏Ä‰∏™ÈÄöÁî®ÂØÑÂ≠òÂô® = 64 bit = 8 bytes

| Ê¶ÇÂøµ        | Áõ∏ÂΩì‰∫é             |
| --------- | --------------- |
| ÂØÑÂ≠òÂô®       | Âé®Â∏àÊâã‰∏äÁöÑÂàÄ/Ë∞ÉÊñôÔºàÁ´ãÂàªË¶ÅÁî®Ôºâ |
| CPU Cache | Ê°åÂ≠ê‰∏äÊîæÁùÄÁöÑË∞ÉÊñôÊû∂ÔºàÂ§áÁî®Ôºâ   |
| RAM ÂÜÖÂ≠ò    | Âé®ÊàøÂÇ®Áâ©ÊüúÔºàÊâÄÊúâÊùêÊñôÔºâ     |
| Á°¨Áõò        | ‰ªìÂ∫ìÔºàÂ§ßÁöÑ„ÄÅÊÖ¢ÁöÑÔºâ       |

**‰æãÂ≠êÔºöÊâßË°å c = a + b**
CPU ÂÅöÁöÑ‰∫ãÊÉÖÂ§ßÊ¶ÇÊòØÔºö

‰ªéÂÜÖÂ≠òÊää a ÊãøËøõÂØÑÂ≠òÂô® R1
‰ªéÂÜÖÂ≠òÊää b ÊãøËøõÂØÑÂ≠òÂô® R2
ÂÅö R1 + R2 ‚Üí ÊîæËøõÂØÑÂ≠òÂô® R3
Êää R3 ÂÜôÂõûÂÜÖÂ≠ò‰ΩçÁΩÆ c

‰ª£Á†ÅÁúãËµ∑Êù•ÁÆÄÂçï ,Â∫ïÂ±ÇÂç¥ÊòØÔºöÂÜÖÂ≠ò ‚Üî ÂØÑÂ≠òÂô® ‚Üî ALUÔºàÁÆóÊúØÂçïÂÖÉÔºâ

---

## Thread
**What is program**:
A program is a sequence of instructions written in a programming language.
**What is process:**
A process is an instance of a program that is being executed. (e.g. tabs in chrome).
**What is thread:**
A thread is a unit of execution within a process (e.g. Apache Server).


---
## Cache
**Concept:** 
cpu always first check if the needed data is already in the cache.
if not exist, cache miss -> the required data will be copied from RAM to cache (sequence of the data)
if exist -> cache hit

**Locality of Reference:**
- **Temporal Locality**
	- recent accessed data is likely to be accessed again in the near future.
- **Spatial Locality**
	- Data that is physically close in memory tends to be accessed around the same time. (likely access the nearby memory shortly after) (also load the adjacent data)

**Cache Memory structure**
- **Instruction cache**
	- Small hardware component that accelerates the fetching and execution of CPU commands
- **Data cache**
	- Used to speed up data access
(N-Way set associative cache)
(Fully associative cache: Increased power consumption and larger chip area)
(Directed-mapped cache)

Cache replacement algorithm

---

## Heap / Stack
two areas in the RAM
Stack : an area of memory that has a predefined size, usually around 2MB, 
Heap: also might have predefined size, but can grow and change as the application goes on.


**Stack** literally just stack data on top of each other, so thats the reason why the allocation is fast.

**Heap** is not contiguous, every time when calling `new` or `malloc`, the instruction go through the memory, and finding any area that can fit the data. (return the pointer of that memory, also record some other infos such as the size of the allocation etc)
- if you asking for more memory for that location, the application need to ask the operation system for some memory (can be expensive)

**Compare**: Allocation on heap is expensive, allocation on stack is just one CPU instruction


| Âå∫Âüü        | ‰ΩøÁî®ÊñπÂºè             | ÂØπ cache ÁöÑÂΩ±Âìç                |
| --------- | ---------------- | -------------------------- |
| **Stack** | Â±ÄÈÉ®ÂèòÈáè„ÄÅÂáΩÊï∞Ë∞ÉÁî®        | È´òÂ±ÄÈÉ®ÊÄßÔºåÈ°∫Â∫èËÆøÈóÆÔºåÂ§öÊï∞ÊÉÖÂÜµ cache ÂèãÂ•Ω    |
| **Heap**  | malloc/new ÂàÜÈÖçÁöÑÂØπË±° | ÂèØËÉΩÂæàÂàÜÊï£ÔºåÊåáÈíàÈìæË°®„ÄÅÊ†ëÊõ¥ÂÆπÊòì cache miss |
Êï∞ÁªÑÊîæÂú® stack ‰∏äÔºåËøûÁª≠Â≠òÂÇ®ÔºåCPU ‰∏ÄÊ¨°Êäì‰∏Ä‰∏≤Ôºå**cache hit È´ò**„ÄÇ  
ÈìæË°®Âú® heap ‰∏äÔºå‰∏Ä‰∏™ node Ë∑≥‰∏Ä‰∏™Âú∞ÂùÄÔºå**ÂÆπÊòì cache miss**„ÄÇ
Stack: Â∞èÁöÑÔºåÁîüÂëΩÂë®ÊúüÁ°ÆÂÆöÔºåÂáΩÊï∞Ë∞ÉÁî®ÂÆåÂ∞±Êâî
heap: ÁîüÂëΩÂë®ÊúüÂ§çÊùÇÁöÑÔºà‰∏çÊòØÂçïÁ∫ØÁöÑÂáΩÊï∞‰ΩúÁî®ÂüüÈÇ£‰πàÁÆÄÂçïÁöÑÔºâÔºåÈúÄË¶ÅËá™Â∑±Áî≥ËØ∑ÈáäÊîæÔºåÁÅµÊ¥ªÁÆ°ÁêÜËµÑÊ∫êÊ±†

```
//heap:
struct vector3{
float x, y, z;
};

int main(){
	//stack
	int value = 5;
	int array[5];
	vector3 vector;
	
	//heap
	int* hvalue = new int;
	*hvalue = 5;
	int* harray = new int[5];
	vector3* hvector = new vector3();
}
```


when to use heap:
- when you cant use stack
- when you need the lifetime to be longer than the scope of your function.
- specifically need more data, for example loading texture like 15MB (CPU load in  heap, then upload to GPU vram)
- 
what happen when calling `new`:
- go through all memory
- find the proper size free memory
- allocate


If you pre-allocate the size of memory on the heap, before you ran the program, then you allocate the data from the pre-allocated, then similar to stack . 

stack ‰ºòÂäøÂú®‰∫éÔºö
- ÁªùÂØπÁÆÄÂçï
- ÁªùÂØπËøûÁª≠
- Á°¨‰ª∂ÂèãÂ•Ω
- Á≥ªÁªü‰øùËØÅÊó†Á¢éÁâá
    
heap Â∞±ÁÆó‰Ω† reserveÔºå‰πü‰∏ç‰ºö magically ÂÖ∑Â§áËøô‰∫õÁ°¨‰ª∂ÁâπÊÄß„ÄÇ

---



> implement a thread-safe queue  
> fix a race condition  
> write a basic class w/ move semantics  
> explain cache locality / why data-oriented design matters  
> talk through how you'd architect a real-time update loop

At most, you might get a concept like:

> How does the GPU pipeline differ from CPU execution?

or

> How would you profile and optimize a stuttering render frame?

Brush up on:

- Smart pointers / move semantics
    
- RAII
    
- Data structures & algorithms (medium-tier)
    
- Basic concurrency (mutex, lock, threads)
    
- Networking basics (latency, sync, tick rate)
    
- Memory + performance tuning strategies
    

If you know _conceptually_ what a ray-sphere test looks like, cool ‚Äî but don‚Äôt waste energy grinding BRDFs and BVH traversal unless they already told you it's a rendering-engine role.




For a grad SWE role like this ‚Äî even one with graphics vibes ‚Äî the technical portion usually looks like:

**1. LeetCode-style problem solving**
- Arrays, strings, hash maps
- BFS/DFS basics
- Simple DP sometimes
- Reasonable difficulty (easy ‚Üí medium)
- Focus on clarity & thought process, not trick puzzles
    

**2. C++ fundamentals**

- Memory (stack vs heap, RAII, smart pointers)
    
- References vs pointers
    
- Copy vs move semantics
    
- Object lifetime
    
- Maybe very simple class design
    

**3. Concurrency basics**  
Not HPC-research level ‚Äî but things like:
- What is a mutex?
    
- What is a race condition?
    
- What is deadlock?
    
- Why thread safety matters in real-time systems
    
- Maybe implement a thread-safe queue or explain how to
    

**4. Performance awareness**  
Real-time virtual worlds = latency matters.

Questions like:

- How do you avoid memory fragmentation?
- Why does cache locality matter?
    
- How would you profile bottlenecks?
    

Think high-level reasoning, not implement-a-lock-free-queue-from-scratch.



|Priority|Topic|Reason|
|---|---|---|
|‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è|LeetCode easy/medium|Core SWE filter|
|‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è|Modern C++ basics|Your selling point|
|‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è|Memory & performance|Real-time systems fit|
|‚≠êÔ∏è‚≠êÔ∏è‚≠êÔ∏è|Concurrency basics|Virtual worlds, networking|
|‚≠êÔ∏è‚≠êÔ∏è|High-level networking|Show curiosity about distributed systems|
|‚≠êÔ∏è|Vulkan/graphics context|Only to add flavor, not main event|


Ah, yeah ‚Äî ‚Äúhigh performance‚Äù in software engineering isn‚Äôt just ‚Äúoh cool I know threads!‚Äù üòÑ  
Multithreading and multiprocessing are _part_ of the story, but they‚Äôre just tools in the toolbox.

### ‚úÖ What ‚Äúhigh performance‚Äù _actually_ means

A high-performance engineer understands how to build systems that:

- **Use CPU, memory, I/O efficiently**
    
- **Scale gracefully** as load grows
    
- Handle **latency + throughput trade-offs**
    
- **Profile, measure, and optimize** bottlenecks
    
- Choose the **right algorithms & data structures**
    
- Understand **concurrency models** (not just ‚Äúthreads good‚Äù)
    
- Consider **caching, batching, vectorization, streaming**
    
- Work with **low-latency networking** or **high-throughput pipelines**
    
- Optimize **database queries, indexes, storage patterns**
    
- Think about **system architecture** (event-driven? async I/O? queueing?)
    
- Prioritize **observability + instrumentation** (metrics, tracing)
    

High performance could show up in areas like:

- High-freq trading systems (microseconds matter)
    
- Big data pipelines (GB/TB per minute)
    
- Real-time gaming engines
    
- ML model inference serving at scale
    
- Database/OS/kernel level work
    
- Even efficient frontend rendering & WASM work!
    

Threads are just _one chapter in a whole book_.

---

### ‚úÖ If someone claims ‚ÄúI build high-performance systems‚Äù ‚Äî you can test them by asking:

**Concepts**

- ‚ÄúHow do you identify performance bottlenecks in a system?‚Äù
    
- ‚ÄúExplain the difference between concurrency and parallelism.‚Äù
    
- ‚ÄúWhen are threads _bad_?‚Äù
    
- ‚ÄúWhat‚Äôs the difference between latency and throughput?‚Äù
    
- ‚ÄúMemory vs CPU-bound workloads ‚Äî how do you optimize each?‚Äù
    

**Tools**

- ‚ÄúWhat profilers or benchmarking tools have you used?‚Äù
    
- ‚ÄúHow do you measure performance in prod? What metrics matter?‚Äù
    

**Trade-offs**

- ‚ÄúWhen would you choose async I/O over multithreading?‚Äù
    
- ‚ÄúTell me about a time you made something _slower_ first to make it _scale better_.‚Äù
    

**System-thinking questions**

- ‚ÄúHow would you design a high-throughput event processing system?‚Äù
    
- ‚ÄúHow do you ensure performance stays good over time as traffic grows?‚Äù
    

---

### üí° Bonus: code-level signals

A real performance-minded engineer talks about:

- O(N) vs O(N log N) thinking
    
- Cache locality, SIMD, vectorization
    
- Memory fragmentation, garbage collection behavior
    
- Lock-free data structures
    
- DB index strategy / query plans
    
- Batching / rate limiting / circuit breaking / prefetching
    
- Avoiding premature optimization (measure first!)
    

---

### üéØ TL;DR

> High performance is about **designing, measuring, and optimizing systems for efficiency and scale**, not just ‚Äúusing threads.‚Äù

---

If you want, I can also:

üîç give you a mock interview question set  
üöÄ walk through a hands-on performance tuning example  
üìö point you to resources to master high-perf engineering

Just say the word üëÄ


## ‚öôÔ∏è _‚ÄúHow do I build a high-performance C++ toy project?‚Äù_

Love this question. The secret is: **start tiny and learn by profiling + optimizing.**  
High-performance thinking is more about _how_ you build than _what_ you build.

Here‚Äôs a great baby-steps roadmap:

### ‚úÖ Step 1: Choose a tiny real-time project

Good starters:

- Particle system (100k particles moving)
    
- Boids (flocking simulation)
    
- Simple physics sim (balls bouncing in 2D)
    
- Job system / thread pool mini-engine
    
- Small multiplayer demo (even just moving dots synced over network!)
    

These are _bite-size but performance-sensitive_.

Pick one and commit to ‚Äúsmall but polished,‚Äù not big + abandoned.

### ‚úÖ Step 2: Build baseline version

Write the simplest thing that works, even if slow.

### ‚úÖ Step 3: Profile it

Use tools like:

- `perf` (Linux)
    
- Visual Studio profiler
    
- Tracy (super nice for game-style profiling)
    
- Renderdoc if it's graphical
    

Goal: **find actual bottlenecks, don‚Äôt guess.**

### ‚úÖ Step 4: Optimize with purpose

Focus on learning:

- cache-friendly data layout (SoA vs AoS)
    
- avoiding unnecessary allocations
    
- minimizing locks / using lock-free structures where reasonable
    
- memory pools / arenas (basic version!!)
    
- threading work across cores
    
- using modern C++ (move semantics, RAII, smart pointers correctly)
    

Even improving FPS from 30 ‚Üí 200 in a toy sim teaches so much.

### ‚úÖ Step 5: Document what you learned

Recruiters love ‚ÄúI measured ‚Üí I optimized ‚Üí here‚Äôs the result.‚Äù

Even something like:

> Built a particle sim in C++.  
> Started at ~2 million updates/sec.  
> After profiling + data-oriented restructuring: 18 million updates/sec.

Looks like üî• on a CV.

### ‚≠ê Bonus idea:

If you sprinkle Vulkan later, you can turn your sim into a visual demo ‚Äî but **start CPU-side first** to learn performance fundamentals.


- Basic networking
- Database basics
- Operating systems concepts

- Spatial data structures (octrees, quadtrees)
- Basic networking concepts
- Graph algorithms (since their metaverse involves connected worlds)
- Arrays, strings, linked lists
- Trees, BST, graphs
- Hash tables, heaps, stacks, queues
- Sorting, searching algorithms
- Time/space complexity


task synchronization


Process
An instance of a program that is being executed
if any error or memory leak in one process won't hurt execution of another process

Thread:
If one thread has memory leak,  then it can potentially affect the entire process



no shared clock
 no shared memory
 concurrency
 h
overlaying network, 

same computer same colick
no shared memory


distruted computing
building and establishing compyting models for distributed system: cloud c omputing

c


## Types of distributed system
scale: cluster computing and grid computing
cluster: management is centralized
homegeneous
high performance minimum  downtime

gri\d: management is decentralized
getrerogeneous and geographically disperrsed


Architecture model:
- layered model
- object-based model
- data-centered model
- event-based model

advantages of distributed system
- relaibility
- scalability
- fault tolerance
- increase performance

cons:
- very hard to detect failure
- redundancy
- inconsistency
- performance bottlenecks



pitfall: 
- the network is reliable and secure
- topology doesnt change
- zero latency
- 
- 











