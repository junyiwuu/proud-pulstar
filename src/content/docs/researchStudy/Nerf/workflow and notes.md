---
title: nerf workflow and notes
---

## General Information
[yenchenlin/nerf-pytorch](https://github.com/yenchenlin/nerf-pytorch) : simple code. projects/nerf-pytorch.
but slow. around 3 hours on my machine. Low VRAM usage (5gb)

[krrish94/nerf-pytorch](https://github.com/krrish94/nerf-pytorch) : full project and configuration. projects/nerf2/nerf-pytorch. faster, around 1 hour on my machine. 20gb VRAM
LLFF: Local Light Field Fusion. google dataset.
npy file: each line is camera's metadata. not the image itself. 


## Content
run_nerf_helper: 
* img2mse
* mse2psnr
* to8b
* Positional Encoding
* NeRF model




å®ƒæŠŠç©ºé—´ç‚¹ `x` å’Œè§‚å¯Ÿæ–¹å‘ `d` ä¸€èµ·ä½œä¸ºè¾“å…¥ï¼Œä½†ä¸æ˜¯**ç›´æ¥æ‹¼**ä¸€å¼€å§‹å°±è¿›ç½‘ç»œï¼Œè€Œæ˜¯ï¼š
- å…ˆåªå¤„ç† `x`ï¼Œå¾—åˆ°ä¸€ä¸ª feature `h(x)`
- ç„¶åå†æ‹¼ `d`ï¼Œè¿›ä¸€æ­¥å¾—åˆ°é¢œè‰² `rgb`
  

## Functions learning
**torch.meshgrid** : 
```

x = torch.tensor([1, 2, 3])
y = torch.tensor([4, 5])
xx, yy = torch.meshgrid(x, y, indexing='ij')

# all values on x axis
xx =
[[1, 1],
 [2, 2],
 [3, 3]]

# all values on y axis
yy =
[[4, 5],
 [4, 5],
 [4, 5]]

# then it equals to create these points: 
coords = torch.stack([xx, yy], dim=-1) # shape: [H, W, 2]
tensor([[[1, 4],
         [1, 5]],

        [[2, 4],
         [2, 5]],

        [[3, 4],
         [3, 5]]])
```

`ij`:  
* x copy twice via horizontal, because y size is 2
* y copy three times vertically, because x size is 3
`xy`:
* x copy twice vertically because y size is 2
* y copy three times horizontally because x size  is 3

```
x = torch.tensor([1, 2, 3])
y = torch.tensor([4, 5])
xx, yy = torch.meshgrid(x, y, indexing='xy')

xx: 
tensor([[1, 2, 3],
        [1, 2, 3]])
yy:
tensor([[4, 4, 4],
        [5, 5, 5]])

coords = torch.stack([xx, yy], dim=-1) # shape: [H, W, 2]
coords:
tensor([[[1, 4],
         [2, 4],
         [3, 4]], 

        [[1, 5],
         [2, 5],
         [3, 5]]])
```


æ¨ªç€æœ‰å¤šå°‘ä¸ªæ•°ï¼Œå°±æ˜¯æœ€åçš„coordsä¸­çš„wæœ‰å¤šå°‘ä¸ªæ•°
ij æ˜¯æ•°å­¦çŸ©é˜µé£æ ¼ï¼Œè¡Œæ˜¯i åˆ—æ˜¯j
xy æ˜¯å›¾åƒåƒç´ é£æ ¼ï¼Œxæ˜¯æ¨ª yæ˜¯ç«–

---
## NeRF Model
###  NeRFçš„rayç”Ÿæˆå™¨
**Description**: ä»ä¸€å¼ å›¾çš„æ¯ä¸ªåƒç´ å‡ºå‘ï¼Œ generate å¯¹åº”çš„rayèµ·ç‚¹å’Œdirection . (world coordinate)
Input:
Output: 
* `rays_o`, ray origin
* `rays_d`, ray direction


#### ç”¨ç›¸æœºmetadata `K` è¿˜åŸcameraåæ ‡ä¸‹çš„ray direction
```python
dirs = torch.stack([
    (i - cx) / fx,
    -(j - cy) / fy,
    -1
], -1)
```
ç»™å®šä¸€ä¸ªåƒç´ åæ ‡ `(i, j)`ï¼Œæ¨å›è¿™ä¸ªåƒç´ åœ¨ç›¸æœºåæ ‡ç³»ä¸‹çš„æ–¹å‘å‘é‡ `(x, y, z)`ã€‚
**æ€ä¹ˆæ¥çš„ï¼š**
1. **åƒç´ åæ ‡æ˜¯ç”±è¿™ä¸ªç­‰å¼æ¥çš„ï¼ˆæ­£å‘ï¼‰ï¼š**
$$
\begin{bmatrix}
i \\j \\1\end{bmatrix}
=
K\cdot\begin{bmatrix}
x \\y \\z\end{bmatrix}\div z
$$
2.  **(can skip)**
$$
\begin{bmatrix}
i \\j \\1 \end{bmatrix}
=
K \cdot \left(\frac{1}{Z}\begin{bmatrix}
X \\Y \\Z\end{bmatrix}\right)=K \cdot \left( \frac{1}{Z} X_{cam} \right)
$$
* $(i, j)$ï¼šå¯¹åº”çš„å›¾åƒåƒç´ ä½ç½®
* $K \in \mathbb{R}^{3\times3}$ï¼šç›¸æœºå†…å‚çŸ©é˜µï¼ˆä¸éœ€è¦è½¬ç½®ï¼‰
* $X_{cam}$ï¼šç‚¹åœ¨ç›¸æœºåæ ‡ç³»ä¸­çš„ä½ç½®ï¼ˆç‰©ç†åæ ‡ï¼‰
  
3. **åæ¨**
$$
\begin{bmatrix}
x \\y \\z\end{bmatrix}
=z \cdot K^{-1}\cdot
\begin{bmatrix}
i \\j \\1\end{bmatrix}
$$
ä½†æˆ‘ä»¬ä¸å…³å¿ƒ `z` çš„å®é™…å¤§å°ï¼ˆå› ä¸ºæ˜¯æ–¹å‘å‘é‡ï¼Œå½’ä¸€åŒ–å°±å¯ä»¥ï¼‰ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç›´æ¥è®¾å®š `z = -1`ï¼Œä»£è¡¨â€œæœç€ -z çœ‹â€ã€‚

4. **æ‰‹åŠ¨æ±‚ $K^{-1}$ï¼ˆå› ä¸ºæ˜¯ upper triangular çŸ©é˜µï¼‰ï¼š**
$$
K^{-1} =\begin{bmatrix}
1/f_x & 0 & -c_x/f_x \\0 & 1/f_y & -c_y/f_y \\0 & 0 & 1\end{bmatrix}
$$
5. **ä»£å…¥è®¡ç®—**
$$
K^{-1}\begin{bmatrix}
i \\j \\1\end{bmatrix}
=\begin{bmatrix}(i - c_x)/f_x \\(j - c_y)/f_y \\1
\end{bmatrix}
$$
6. **å¯¹åº”çŸ©é˜µä¸Šçš„ä½ç½®**
ç»™å®šåƒç´ åæ ‡ `(i, j)`ï¼Œç›¸æœºå†…å‚ï¼š
* $f_x = K[0][0]$
* $f_y = K[1][1]$
* $c_x = K[0][2]$
* $c_y = K[1][2]$

4. **å°±å¾—åˆ°äº†å‰é¢çš„é‚£ä¸ªä»£ç **
  

>é€†çŸ©é˜µçš„ä¾‹å­ inverse matrixï¼š 
$$A = \begin{bmatrix}a & b \\c & d\end{bmatrix}$$
  å®ƒçš„é€†çŸ©é˜µæ˜¯ï¼š
 $$A^{-1} = \frac{1}{ad - bc}\begin{bmatrix}d & -b \\-c & a\end{bmatrix}$$
 åªè¦ $ad - bc \ne 0$ï¼Œå°±å¯é€†ã€‚





---

## âœ… ä½ å¯ä»¥è¿™æ ·æ‹†åˆ†ä¸‰å±‚æ¥æ•´ç†

### ğŸŸ© 1. æ•°æ®å¤„ç†å±‚
- è¯»å›¾åƒ â†’ è¯» camera pose â†’ ç”Ÿæˆ ray
- embedder æŠŠ ray ä¸Šçš„ 3D ç‚¹åš sin/cos ç¼–ç 
    

### ğŸŸ¨ 2. ç½‘ç»œå±‚ï¼ˆNeRFï¼‰
- æ¯ä¸ªç‚¹ `(x, d)` å–‚è¿›ç½‘ç»œ â†’ è¾“å‡º `(rgb, Ïƒ)`
- å¤šä¸ªç‚¹æŒ‰ ray é¡ºåºåš volume rendering â†’ æ‹¼å‡ºä¸€ä¸ªåƒç´ å€¼

### ğŸŸ¥ 3. è®­ç»ƒå±‚
- æŠŠæ¸²æŸ“å‡ºæ¥çš„åƒç´ å’ŒçœŸå®å›¾åƒæ¯” â†’ MSE loss
- åå‘ä¼ æ’­æ›´æ–°ç½‘ç»œå‚æ•°
    


|åŠŸèƒ½|ä»£ç |
|---|---|
|åŠ è½½å›¾åƒ + pose|`load_blender_data()`|
|ç”Ÿæˆ ray|`get_rays()`|
|ç‚¹ç¼–ç |`Embedder.embed()`|
|ç½‘ç»œå‰å‘|`run_network()` + `network_query_fn`|
|æ¸²æŸ“åƒç´ |`render_rays()` â†’ `raw2outputs()`|
|ä¼˜åŒ–|`train()` ä¸­è®¡ç®— lossã€backward|

---

æ•´å¥—æµç¨‹ `å›¾åƒ â†’ æ¨¡å‹ â†’ æ¸²æŸ“ â†’ loss` 